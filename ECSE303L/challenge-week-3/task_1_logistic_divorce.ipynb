{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMHjtVPbyaKP"
   },
   "source": [
    "## Logistic Regression Model for Divorce Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Implement  linear regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJi26z8awmSD"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/divorce.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set. Dataset is based on rating for questionnaire filled by people who already got divorse and those who is happily married.<br><br>\n",
    "\n",
    "[//]: # \"The dataset is available at http://archive.ics.uci.edu/ml/machine-learning-databases/00520/data.zip. Unzip the file and use either CSV or xlsx file.<br>\"\n",
    "\n",
    "\n",
    "#### Features (X)\n",
    "1. Atr1 - If one of us apologizes when our discussion deteriorates, the discussion ends. (Numeric | Range: 0-4)\n",
    "2. Atr2 - I know we can ignore our differences, even if things get hard sometimes. (Numeric | Range: 0-4)\n",
    "3. Atr3 - When we need it, we can take our discussions with my spouse from the beginning and correct it. (Numeric | Range: 0-4)\n",
    "4. Atr4 - When I discuss with my spouse, to contact him will eventually work. (Numeric | Range: 0-4)\n",
    "5. Atr5 - The time I spent with my wife is special for us. (Numeric | Range: 0-4)\n",
    "6. Atr6 - We don't have time at home as partners. (Numeric | Range: 0-4)\n",
    "7. Atr7 - We are like two strangers who share the same environment at home rather than family. (Numeric | Range: 0-4)\n",
    "\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "&emsp;.<br>\n",
    "<br>\n",
    "54. Atr54 - I'm not afraid to tell my spouse about her/his incompetence. (Numeric | Range: 0-4)\n",
    "<br><br>\n",
    "Take a look above at the source of the original dataset for more details.\n",
    "\n",
    "#### Target (y)\n",
    "55. Class: (Binary | 1 => Divorced, 0 => Not divorced yet)\n",
    "\n",
    "#### Objective\n",
    "To gain understanding of logistic regression through implementing the model from scratch\n",
    "\n",
    "#### Tasks\n",
    "- Download and load the data (csv file contains ';' as delimiter)\n",
    "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function). This is for input to the bias $w_0$\n",
    "- Define X matrix (independent features) and y vector (target feature) as numpy arrays\n",
    "- Print the shape and datatype of both X and y\n",
    "[//]: # \"- Dataset contains missing values, hence fill the missing values (NA) by performing missing value prediction\"\n",
    "[//]: # \"- Since the all the features are in higher range, columns can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (sklearn.preprocessing.StandardScaler)\"\n",
    "- Split the dataset into 85% for training and rest 15% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Follow logistic regression class and fill code where highlighted:\n",
    "    - Write sigmoid function to predict probabilities\n",
    "    - Write log likelihood function\n",
    "    - Write fit function where gradient ascent is implemented\n",
    "    - Write predict_proba function where we predict probabilities for input data\n",
    "- Train the model\n",
    "- Write function for calculating accuracy\n",
    "- Compute accuracy on train and test data\n",
    "\n",
    "#### Further Fun (will not be evaluated)\n",
    "- Play with learning rate and max_iterations\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Train model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffle training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21J6cpd_wmSE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SL1fdNt1k3Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9av7W-wowmSI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...    Atr46  \\\n",
       "0     2     2     4     1     0     0     0     0     0      0  ...        2   \n",
       "1     4     4     4     4     4     0     0     4     4      4  ...        2   \n",
       "2     2     2     2     2     1     3     2     1     1      2  ...        3   \n",
       "3     3     2     3     2     3     3     3     3     3      3  ...        2   \n",
       "4     2     2     1     1     1     1     0     0     0      0  ...        2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = pd.read_csv(\"data/divorce.csv\",sep=';')\n",
    "data.head()\n",
    "# Set delimiter to semicolon(;) in case of unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n",
    "data.insert(0,'w0',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV1jGAQxwmSP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   w0  Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  ...    Atr46  \\\n",
       "0   1     2     2     4     1     0     0     0     0     0  ...        2   \n",
       "1   1     4     4     4     4     4     0     0     4     4  ...        2   \n",
       "2   1     2     2     2     2     1     3     2     1     1  ...        3   \n",
       "3   1     3     2     3     2     3     3     3     3     3  ...        2   \n",
       "4   1     2     2     1     1     1     1     0     0     0  ...        2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dataframe rows just to see some samples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joRU6dWxwmSR"
   },
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "\n",
    "X = data.iloc[:,:55]\n",
    "y = data.iloc[:,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAyM-CYCwmSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: Type-w0       int64\n",
      "Atr1     int64\n",
      "Atr2     int64\n",
      "Atr3     int64\n",
      "Atr4     int64\n",
      "Atr5     int64\n",
      "Atr6     int64\n",
      "Atr7     int64\n",
      "Atr8     int64\n",
      "Atr9     int64\n",
      "Atr10    int64\n",
      "Atr11    int64\n",
      "Atr12    int64\n",
      "Atr13    int64\n",
      "Atr14    int64\n",
      "Atr15    int64\n",
      "Atr16    int64\n",
      "Atr17    int64\n",
      "Atr18    int64\n",
      "Atr19    int64\n",
      "Atr20    int64\n",
      "Atr21    int64\n",
      "Atr22    int64\n",
      "Atr23    int64\n",
      "Atr24    int64\n",
      "Atr25    int64\n",
      "Atr26    int64\n",
      "Atr27    int64\n",
      "Atr28    int64\n",
      "Atr29    int64\n",
      "Atr30    int64\n",
      "Atr31    int64\n",
      "Atr32    int64\n",
      "Atr33    int64\n",
      "Atr34    int64\n",
      "Atr35    int64\n",
      "Atr36    int64\n",
      "Atr37    int64\n",
      "Atr38    int64\n",
      "Atr39    int64\n",
      "Atr40    int64\n",
      "Atr41    int64\n",
      "Atr42    int64\n",
      "Atr43    int64\n",
      "Atr44    int64\n",
      "Atr45    int64\n",
      "Atr46    int64\n",
      "Atr47    int64\n",
      "Atr48    int64\n",
      "Atr49    int64\n",
      "Atr50    int64\n",
      "Atr51    int64\n",
      "Atr52    int64\n",
      "Atr53    int64\n",
      "Atr54    int64\n",
      "dtype: object, Shape-(170, 55)\n",
      "y: Type-int64, Shape-(170,)\n"
     ]
    }
   ],
   "source": [
    "X_shape = X.shape\n",
    "X_type  = X.dtypes\n",
    "y_shape = y.shape\n",
    "y_type  = y.dtypes\n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Expected output: </strong><br><br>\n",
    "\n",
    "X: Type-<class 'numpy.ndarray'>, Shape-(170, 55)<br>\n",
    "y: Type-<class 'numpy.ndarray'>, Shape-(170,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdLIVOm127-z"
   },
   "outputs": [],
   "source": [
    "# Check and fill any missing values if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En9Kb9dh2-wm"
   },
   "outputs": [],
   "source": [
    "# Perform standarization (if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8WF-EqO3BEa"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acCATJhI3FdH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (144, 55) , y_train: (144,)\n",
      "X_test: (26, 55) , y_test: (26,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape  = X_test.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
    "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
    "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSa7cW-NwmSd"
   },
   "source": [
    "##### Let us start implementing logistic regression from scratch. Just follow code cells, see hints if required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will build a LogisticRegression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT ANY VARIABLE OR FUNCTION NAME(S) IN THIS CELL\n",
    "# Let's try more object oriented approach this time :)\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000):\n",
    "        '''Initialize variables\n",
    "        Args:\n",
    "            learning_rate  : Learning Rate\n",
    "            max_iterations : Max iterations for training weights\n",
    "        '''\n",
    "        # Initialising all the parameters\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.likelihoods    = []\n",
    "        \n",
    "        # Define epsilon because log(0) is not defined\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        \n",
    "        sig_z = 1/(1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z\n",
    "    \n",
    "    def log_likelihood(self, y_true, y_pred):\n",
    "        '''Calculates maximum likelihood estimate\n",
    "        Remember: y * log(yh) + (1-y) * log(1-yh)\n",
    "        Note: Likelihood is defined for multiple classes as well, but for this dataset\n",
    "        we only need to worry about binary/bernoulli likelihood function\n",
    "        Args:\n",
    "            y_true : Numpy array of actual truth values (num_samples,)\n",
    "            y_pred : Numpy array of predicted values (num_samples,)\n",
    "        Returns:\n",
    "            Log-likelihood, scalar value\n",
    "        '''\n",
    "        # Fix 0/1 values in y_pred so that log is not undefined\n",
    "        y_pred = np.maximum(np.full(y_pred.shape, self.eps), np.minimum(np.full(y_pred.shape, 1-self.eps), y_pred))\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        likelihood =  np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return likelihood\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''Trains logistic regression model using gradient ascent\n",
    "        to gain maximum likelihood on the training data\n",
    "        Args:\n",
    "            X : Numpy array (num_examples, num_features)\n",
    "            y : Numpy array (num_examples, )\n",
    "        Returns: VOID\n",
    "        '''\n",
    "        \n",
    "        num_examples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        \n",
    "        # Initialize weights with appropriate shape\n",
    "        self.weights = np.random.rand(num_features,)\n",
    "        \n",
    "        # Perform gradient ascent\n",
    "        for i in range(self.max_iterations):\n",
    "            # Define the linear hypothesis(z) first\n",
    "            # HINT: what is our hypothesis function in linear regression, remember?\n",
    "            z = np.dot(X,self.weights)\n",
    "            \n",
    "            # Output probability value by appplying sigmoid on z\n",
    "            y_pred = self.sigmoid(z)\n",
    "            \n",
    "            # Calculate the gradient values\n",
    "            # This is just vectorized efficient way of implementing gradient. Don't worry, we will discuss it later.\n",
    "            gradient = np.mean((y-y_pred)*X.T, axis=1)\n",
    "            \n",
    "            # Update the weights\n",
    "            # Caution: It is gradient ASCENT not descent\n",
    "            \n",
    "            self.weights = self.weights+ (self.learning_rate*(gradient))\n",
    "            \n",
    "            # Calculating log likelihood\n",
    "            likelihood = self.log_likelihood(y,y_pred)\n",
    "\n",
    "            self.likelihoods.append(likelihood)\n",
    "    \n",
    "        ### END CODE HERE\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''Predict probabilities for given X.\n",
    "        Remember sigmoid returns value between 0 and 1.\n",
    "        Args:\n",
    "            X : Numpy array (num_samples, num_features)\n",
    "        Returns:\n",
    "            probabilities: Numpy array (num_samples,)\n",
    "        '''\n",
    "        if self.weights is None:\n",
    "            raise Exception(\"Fit the model before prediction\")\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        z = np.dot(X,self.weights)\n",
    "        probabilities = self.sigmoid(z)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        '''Predict/Classify X in classes\n",
    "        Args:\n",
    "            X         : Numpy array (num_samples, num_features)\n",
    "            threshold : scalar value above which prediction is 1 else 0\n",
    "        Returns:\n",
    "            binary_predictions : Numpy array (num_samples,)\n",
    "        '''\n",
    "        # Thresholding probability to predict binary values\n",
    "        binary_predictions = np.array(list(map(lambda x: 1 if x>threshold else 0, self.predict_proba(X))))\n",
    "        \n",
    "        return binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum((np.transpose(np.array([indicator]))-1)*scores - np.log(1. + np.exp(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize logitic regression implemented by you\n",
    "model = MyLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now fit on training data\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phew!! That's a lot of code. But you did it, congrats !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tvMc0OqwmSp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on training data: -0.0511749226559796\n"
     ]
    }
   ],
   "source": [
    "# Train log-likelihood\n",
    "train_log_likelihood = model.log_likelihood(y_train, model.predict_proba(X_train))\n",
    "print(\"Log-likelihood on training data:\", train_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZQ8ITUt4b0N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood on testing data: -0.24392704838492094\n"
     ]
    }
   ],
   "source": [
    "# Test log-likelihood\n",
    "test_log_likelihood = model.log_likelihood(y_test, model.predict_proba(X_test))\n",
    "print(\"Log-likelihood on testing data:\", test_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(model.likelihoods))], model.likelihoods)\n",
    "plt.title(\"Log-Likelihood curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Log-likelihood\")\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's calculate accuracy as well. Accuracy is defined simply as the rate of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    '''Compute accuracy.\n",
    "    Accuracy = (Correct prediction / number of samples)\n",
    "    Args:\n",
    "        y_true : Truth binary values (num_examples, )\n",
    "        y_pred : Predicted binary values (num_examples, )\n",
    "    Returns:\n",
    "        accuracy: scalar value\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    my_accuracy = (np.sum(y_true==y_pred)/y_true.shape[0])*100\n",
    "    ### END CODE HERE\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0       0.0\n",
      "Atr1     0.0\n",
      "Atr2     0.0\n",
      "Atr3     0.0\n",
      "Atr4     0.0\n",
      "Atr5     0.0\n",
      "Atr6     0.0\n",
      "Atr7     0.0\n",
      "Atr8     0.0\n",
      "Atr9     0.0\n",
      "Atr10    0.0\n",
      "Atr11    0.0\n",
      "Atr12    0.0\n",
      "Atr13    0.0\n",
      "Atr14    0.0\n",
      "Atr15    0.0\n",
      "Atr16    0.0\n",
      "Atr17    0.0\n",
      "Atr18    0.0\n",
      "Atr19    0.0\n",
      "Atr20    0.0\n",
      "Atr21    0.0\n",
      "Atr22    0.0\n",
      "Atr23    0.0\n",
      "Atr24    0.0\n",
      "Atr25    0.0\n",
      "Atr26    0.0\n",
      "Atr27    0.0\n",
      "Atr28    0.0\n",
      "Atr29    0.0\n",
      "        ... \n",
      "127      0.0\n",
      "150      0.0\n",
      "32       0.0\n",
      "142      0.0\n",
      "29       0.0\n",
      "99       0.0\n",
      "82       0.0\n",
      "79       0.0\n",
      "115      0.0\n",
      "148      0.0\n",
      "165      0.0\n",
      "72       0.0\n",
      "77       0.0\n",
      "25       0.0\n",
      "81       0.0\n",
      "160      0.0\n",
      "162      0.0\n",
      "39       0.0\n",
      "58       0.0\n",
      "140      0.0\n",
      "88       0.0\n",
      "70       0.0\n",
      "87       0.0\n",
      "36       0.0\n",
      "21       0.0\n",
      "9        0.0\n",
      "103      0.0\n",
      "67       0.0\n",
      "117      0.0\n",
      "47       0.0\n",
      "Length: 199, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avinash\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3755: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on train data\n",
    "print(accuracy(X_train,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0       0.0\n",
      "Atr1     0.0\n",
      "Atr2     0.0\n",
      "Atr3     0.0\n",
      "Atr4     0.0\n",
      "Atr5     0.0\n",
      "Atr6     0.0\n",
      "Atr7     0.0\n",
      "Atr8     0.0\n",
      "Atr9     0.0\n",
      "Atr10    0.0\n",
      "Atr11    0.0\n",
      "Atr12    0.0\n",
      "Atr13    0.0\n",
      "Atr14    0.0\n",
      "Atr15    0.0\n",
      "Atr16    0.0\n",
      "Atr17    0.0\n",
      "Atr18    0.0\n",
      "Atr19    0.0\n",
      "Atr20    0.0\n",
      "Atr21    0.0\n",
      "Atr22    0.0\n",
      "Atr23    0.0\n",
      "Atr24    0.0\n",
      "Atr25    0.0\n",
      "Atr26    0.0\n",
      "Atr27    0.0\n",
      "Atr28    0.0\n",
      "Atr29    0.0\n",
      "        ... \n",
      "Atr51    0.0\n",
      "Atr52    0.0\n",
      "Atr53    0.0\n",
      "Atr54    0.0\n",
      "133      0.0\n",
      "136      0.0\n",
      "168      0.0\n",
      "54       0.0\n",
      "56       0.0\n",
      "144      0.0\n",
      "7        0.0\n",
      "96       0.0\n",
      "121      0.0\n",
      "97       0.0\n",
      "141      0.0\n",
      "5        0.0\n",
      "83       0.0\n",
      "109      0.0\n",
      "55       0.0\n",
      "18       0.0\n",
      "61       0.0\n",
      "101      0.0\n",
      "60       0.0\n",
      "63       0.0\n",
      "153      0.0\n",
      "4        0.0\n",
      "106      0.0\n",
      "161      0.0\n",
      "108      0.0\n",
      "37       0.0\n",
      "Length: 81, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avinash\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3755: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on test data\n",
    "print(accuracy(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: Use Logistic Regression from sklearn on the same dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Define X and y again for sklearn Linear Regression model\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Run the model on testing set\n",
    "- Print 'accuracy' obtained on the testing dataset (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Compare accuracies of your model and sklearn's logistic regression model\n",
    "\n",
    "#### Helpful links\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = data.iloc[:,:55]\n",
    "y = data.iloc[:,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model from sklearn\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred =  model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "#test_accuracy_sklearn = y_test\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#print(f\"\\nAccuracy on testing set: {test_accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_logistic_divorse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
