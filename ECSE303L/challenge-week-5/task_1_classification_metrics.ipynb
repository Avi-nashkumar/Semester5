{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification metrics\n",
    "\n",
    "Choosing right evaluation metrics for the problem is one of the most important aspect of machine learning. Choice of metrics allows us to compare performance of different models and helps in model selection.\n",
    "\n",
    "In this task, we will explore following metrics:\n",
    "- confusion matrix\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "\n",
    "#### Dataset\n",
    "The training dataset is available at \"data/ozone_levels_train.csv\" in the respective challenge' repo.<br>\n",
    "The testing dataset is available at \"data/ozone_levels_test.csv\" in the respective challenge' repo.<br>\n",
    "\n",
    "The dataset is __modified version__ of the dataset 'ozone level' on provided by UCI Machine Learning repository.\n",
    "\n",
    "Original dataset: https://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection\n",
    "\n",
    "#### Objective\n",
    "To learn about classification metrics and compare logistic regression and decision tree on the same dataset\n",
    "\n",
    "#### Tasks\n",
    "- define X(input) and Y(output)\n",
    "- train the decision tree model \n",
    "- train the logistic model\n",
    "- construct a confusion matrix\n",
    "- calculate the classification accurace\n",
    "- calculate the Precision\n",
    "- calculate the Recall\n",
    "- calculate the F1 score\n",
    "- calculate Area Under ROC Curve\n",
    "\n",
    "#### Further fun\n",
    "- Calculate precission and recall\n",
    "- find the area under the curve for Roc metrics\n",
    "- impliment below metrics using inbuilt librarires\n",
    "        confusion matrix\n",
    "        accuracy\n",
    "        precision\n",
    "        recall\n",
    "        f1 score\n",
    "\n",
    "\n",
    "#### Helpful links\n",
    "- Classification metrics with google developers: https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative\n",
    "- classification metrics: https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html\n",
    "- pd.get_dummies() and One Hot Encoding: https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "- Differences between Logistic Regression and a Decision Tree: https://www.geeksforgeeks.org/ml-logistic-regression-v-s-decision-tree-classification/\n",
    "- Decision Tree Classifier by Sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- Understanding classification metrics like Precision, Recall, F-Scores and Confusion matrices: https://nillsf.com/index.php/2020/05/23/confusion-matrix-accuracy-recall-precision-false-positive-rate-and-f-scores-explained/\n",
    "- Understanding the ROC Curve: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Uncomment below 2 lines to ignore warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download data using wget if running on cloud\n",
    "!wget https://github.com/DeepConnectAI/challenge-week-5/raw/master/data/ozone_levels_train.csv\n",
    "!wget https://github.com/DeepConnectAI/challenge-week-5/raw/master/data/ozone_levels_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "train = pd.read_csv('data/ozone_levels_train.csv')\n",
    "test  = pd.read_csv(\"data/ozone_levels_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_0</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>F_9</th>\n",
       "      <th>...</th>\n",
       "      <th>F_63</th>\n",
       "      <th>F_64</th>\n",
       "      <th>F_65</th>\n",
       "      <th>F_66</th>\n",
       "      <th>F_67</th>\n",
       "      <th>F_68</th>\n",
       "      <th>F_69</th>\n",
       "      <th>F_70</th>\n",
       "      <th>F_71</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>26.29</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>5705.0</td>\n",
       "      <td>-19.40</td>\n",
       "      <td>23.40</td>\n",
       "      <td>10315.0</td>\n",
       "      <td>-0.130416</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>15.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>-17.50</td>\n",
       "      <td>19.00</td>\n",
       "      <td>10210.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>31.64</td>\n",
       "      <td>-5.24</td>\n",
       "      <td>5745.0</td>\n",
       "      <td>-16.90</td>\n",
       "      <td>25.90</td>\n",
       "      <td>10175.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>5835.0</td>\n",
       "      <td>-9.55</td>\n",
       "      <td>42.15</td>\n",
       "      <td>10215.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.51</td>\n",
       "      <td>5835.0</td>\n",
       "      <td>32.95</td>\n",
       "      <td>47.30</td>\n",
       "      <td>10170.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F_0  F_1  F_2  F_3  F_4  F_5  F_6  F_7  F_8  F_9  ...    F_63   F_64  F_65  \\\n",
       "0  2.5  3.5  4.4  4.6  4.4  3.5  4.2  4.5  4.2  4.6  ...    0.07  26.29 -2.37   \n",
       "1  1.2  0.7  0.3  0.1  0.3  0.4  0.6  1.1  1.9  2.4  ...    0.24  15.80  2.10   \n",
       "2  0.1  0.4  0.6  0.4  1.0  1.7  0.7  1.3  2.3  2.4  ...    0.12  31.64 -5.24   \n",
       "3  0.6  0.9  1.0  0.6  0.7  0.7  0.8  1.4  2.6  2.6  ...    0.19   1.22 -0.28   \n",
       "4  0.1  0.4  0.3  0.1  0.1  0.0  0.9  1.9  2.0  2.0  ...    0.87   1.65  1.51   \n",
       "\n",
       "     F_66   F_67   F_68     F_69       F_70  F_71  class  \n",
       "0  5705.0 -19.40  23.40  10315.0  -0.130416  0.00    0.0  \n",
       "1  5710.0 -17.50  19.00  10210.0  15.000000  0.00    0.0  \n",
       "2  5745.0 -16.90  25.90  10175.0  85.000000  0.00    0.0  \n",
       "3  5835.0  -9.55  42.15  10215.0   5.000000  0.00    0.0  \n",
       "4  5835.0  32.95  47.30  10170.0  15.000000  0.97    0.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore train dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1775 entries, 0 to 1774\n",
      "Data columns (total 73 columns):\n",
      "F_0      1775 non-null float64\n",
      "F_1      1775 non-null float64\n",
      "F_2      1775 non-null float64\n",
      "F_3      1775 non-null float64\n",
      "F_4      1775 non-null float64\n",
      "F_5      1775 non-null float64\n",
      "F_6      1775 non-null float64\n",
      "F_7      1775 non-null float64\n",
      "F_8      1775 non-null float64\n",
      "F_9      1775 non-null float64\n",
      "F_10     1775 non-null float64\n",
      "F_11     1775 non-null float64\n",
      "F_12     1775 non-null float64\n",
      "F_13     1775 non-null float64\n",
      "F_14     1775 non-null float64\n",
      "F_15     1775 non-null float64\n",
      "F_16     1775 non-null float64\n",
      "F_17     1775 non-null float64\n",
      "F_18     1775 non-null float64\n",
      "F_19     1775 non-null float64\n",
      "F_20     1775 non-null float64\n",
      "F_21     1775 non-null float64\n",
      "F_22     1775 non-null float64\n",
      "F_23     1775 non-null float64\n",
      "F_24     1775 non-null float64\n",
      "F_25     1775 non-null float64\n",
      "F_26     1775 non-null float64\n",
      "F_27     1775 non-null float64\n",
      "F_28     1775 non-null float64\n",
      "F_29     1775 non-null float64\n",
      "F_30     1775 non-null float64\n",
      "F_31     1775 non-null float64\n",
      "F_32     1775 non-null float64\n",
      "F_33     1775 non-null float64\n",
      "F_34     1775 non-null float64\n",
      "F_35     1775 non-null float64\n",
      "F_36     1775 non-null float64\n",
      "F_37     1775 non-null float64\n",
      "F_38     1775 non-null float64\n",
      "F_39     1775 non-null float64\n",
      "F_40     1775 non-null float64\n",
      "F_41     1775 non-null float64\n",
      "F_42     1775 non-null float64\n",
      "F_43     1775 non-null float64\n",
      "F_44     1775 non-null float64\n",
      "F_45     1775 non-null float64\n",
      "F_46     1775 non-null float64\n",
      "F_47     1775 non-null float64\n",
      "F_48     1775 non-null float64\n",
      "F_49     1775 non-null float64\n",
      "F_50     1775 non-null float64\n",
      "F_51     1775 non-null float64\n",
      "F_52     1775 non-null float64\n",
      "F_53     1775 non-null float64\n",
      "F_54     1775 non-null float64\n",
      "F_55     1775 non-null float64\n",
      "F_56     1775 non-null float64\n",
      "F_57     1775 non-null float64\n",
      "F_58     1775 non-null float64\n",
      "F_59     1775 non-null float64\n",
      "F_60     1775 non-null float64\n",
      "F_61     1775 non-null float64\n",
      "F_62     1775 non-null float64\n",
      "F_63     1775 non-null float64\n",
      "F_64     1775 non-null float64\n",
      "F_65     1775 non-null float64\n",
      "F_66     1775 non-null float64\n",
      "F_67     1775 non-null float64\n",
      "F_68     1775 non-null float64\n",
      "F_69     1775 non-null float64\n",
      "F_70     1775 non-null float64\n",
      "F_71     1775 non-null float64\n",
      "class    1775 non-null float64\n",
      "dtypes: float64(73)\n",
      "memory usage: 1012.4 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_0</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>F_9</th>\n",
       "      <th>...</th>\n",
       "      <th>F_63</th>\n",
       "      <th>F_64</th>\n",
       "      <th>F_65</th>\n",
       "      <th>F_66</th>\n",
       "      <th>F_67</th>\n",
       "      <th>F_68</th>\n",
       "      <th>F_69</th>\n",
       "      <th>F_70</th>\n",
       "      <th>F_71</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>27.66</td>\n",
       "      <td>11.94</td>\n",
       "      <td>5605.0</td>\n",
       "      <td>10.70</td>\n",
       "      <td>31.95</td>\n",
       "      <td>10240.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>19.22</td>\n",
       "      <td>18.21</td>\n",
       "      <td>5515.0</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>42.00</td>\n",
       "      <td>10065.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>14.22</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>5690.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>32.70</td>\n",
       "      <td>10105.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>13.07</td>\n",
       "      <td>9.15</td>\n",
       "      <td>5820.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>39.35</td>\n",
       "      <td>10220.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>5910.0</td>\n",
       "      <td>27.70</td>\n",
       "      <td>43.70</td>\n",
       "      <td>10110.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F_0  F_1  F_2  F_3  F_4  F_5  F_6  F_7  F_8  F_9  ...    F_63   F_64  \\\n",
       "0  4.0  3.7  2.9  3.6  2.4  2.9  2.0  2.0  3.2  3.8  ...    0.47  27.66   \n",
       "1  2.2  2.9  3.4  4.2  4.7  4.7  5.3  4.9  5.2  6.0  ...    0.20  19.22   \n",
       "2  2.7  2.2  2.3  2.5  2.6  2.9  3.2  2.9  3.6  4.2  ...    0.10  14.22   \n",
       "3  1.5  1.3  1.8  1.4  1.2  1.7  1.6  1.4  1.6  3.0  ...    0.54  13.07   \n",
       "4  2.6  2.7  2.2  1.4  1.6  1.9  2.6  3.5  4.2  4.5  ...    0.26  -1.52   \n",
       "\n",
       "    F_65    F_66   F_67   F_68     F_69  F_70  F_71  class  \n",
       "0  11.94  5605.0  10.70  31.95  10240.0  10.0   0.0    0.0  \n",
       "1  18.21  5515.0 -10.10  42.00  10065.0  25.0   0.0    0.0  \n",
       "2  -2.98  5690.0   0.70  32.70  10105.0 -55.0   0.0    0.0  \n",
       "3   9.15  5820.0   1.95  39.35  10220.0 -25.0   0.0    0.0  \n",
       "4  -4.53  5910.0  27.70  43.70  10110.0 -30.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore test dataset\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 761 entries, 0 to 760\n",
      "Data columns (total 73 columns):\n",
      "F_0      761 non-null float64\n",
      "F_1      761 non-null float64\n",
      "F_2      761 non-null float64\n",
      "F_3      761 non-null float64\n",
      "F_4      761 non-null float64\n",
      "F_5      761 non-null float64\n",
      "F_6      761 non-null float64\n",
      "F_7      761 non-null float64\n",
      "F_8      761 non-null float64\n",
      "F_9      761 non-null float64\n",
      "F_10     761 non-null float64\n",
      "F_11     761 non-null float64\n",
      "F_12     761 non-null float64\n",
      "F_13     761 non-null float64\n",
      "F_14     761 non-null float64\n",
      "F_15     761 non-null float64\n",
      "F_16     761 non-null float64\n",
      "F_17     761 non-null float64\n",
      "F_18     761 non-null float64\n",
      "F_19     761 non-null float64\n",
      "F_20     761 non-null float64\n",
      "F_21     761 non-null float64\n",
      "F_22     761 non-null float64\n",
      "F_23     761 non-null float64\n",
      "F_24     761 non-null float64\n",
      "F_25     761 non-null float64\n",
      "F_26     761 non-null float64\n",
      "F_27     761 non-null float64\n",
      "F_28     761 non-null float64\n",
      "F_29     761 non-null float64\n",
      "F_30     761 non-null float64\n",
      "F_31     761 non-null float64\n",
      "F_32     761 non-null float64\n",
      "F_33     761 non-null float64\n",
      "F_34     761 non-null float64\n",
      "F_35     761 non-null float64\n",
      "F_36     761 non-null float64\n",
      "F_37     761 non-null float64\n",
      "F_38     761 non-null float64\n",
      "F_39     761 non-null float64\n",
      "F_40     761 non-null float64\n",
      "F_41     761 non-null float64\n",
      "F_42     761 non-null float64\n",
      "F_43     761 non-null float64\n",
      "F_44     761 non-null float64\n",
      "F_45     761 non-null float64\n",
      "F_46     761 non-null float64\n",
      "F_47     761 non-null float64\n",
      "F_48     761 non-null float64\n",
      "F_49     761 non-null float64\n",
      "F_50     761 non-null float64\n",
      "F_51     761 non-null float64\n",
      "F_52     761 non-null float64\n",
      "F_53     761 non-null float64\n",
      "F_54     761 non-null float64\n",
      "F_55     761 non-null float64\n",
      "F_56     761 non-null float64\n",
      "F_57     761 non-null float64\n",
      "F_58     761 non-null float64\n",
      "F_59     761 non-null float64\n",
      "F_60     761 non-null float64\n",
      "F_61     761 non-null float64\n",
      "F_62     761 non-null float64\n",
      "F_63     761 non-null float64\n",
      "F_64     761 non-null float64\n",
      "F_65     761 non-null float64\n",
      "F_66     761 non-null float64\n",
      "F_67     761 non-null float64\n",
      "F_68     761 non-null float64\n",
      "F_69     761 non-null float64\n",
      "F_70     761 non-null float64\n",
      "F_71     761 non-null float64\n",
      "class    761 non-null float64\n",
      "dtypes: float64(73)\n",
      "memory usage: 434.1 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X_train = train.drop('class', axis=1)\n",
    "X_test  = test.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "y_test  = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1775, 72) , y_train: (1775,)\n",
      "X_test: (761, 72) , y_test: (761,)\n"
     ]
    }
   ],
   "source": [
    "# Print shape of X_train, X_test, y_train, y_test\n",
    "X_train_shape = X_train.shape\n",
    "y_train_shape = y_train.shape\n",
    "X_test_shape  = X_test.shape\n",
    "y_test_shape  = y_test.shape\n",
    "\n",
    "print(f\"X_train: {X_train_shape} , y_train: {y_train_shape}\")\n",
    "print(f\"X_test: {X_test_shape} , y_test: {y_test_shape}\")\n",
    "assert (X_train.shape[0]==y_train.shape[0] and X_test.shape[0]==y_test.shape[0]), \"Check your splitting carefully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "# Classifier 1 - Logistic regression\n",
    "clf1 = LogisticRegression(max_iter=10000)\n",
    "# Classifier 2 - Decision tree\n",
    "clf2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train both the models on training dataset\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9671484888304862, 0.9434954007884363)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on testing data\n",
    "y_pred_lr = clf1.predict(X_test)\n",
    "y_pred_dt = clf2.predict(X_test)\n",
    "sum(y_pred_lr ==  y_test)/ len(y_test) , sum(y_pred_dt ==  y_test)/ len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary building blocks of classification metrics\n",
    "\n",
    "A __TRUE POSITIVE (TP)__ is an outcome where the model correctly predicts the positive class.\n",
    "\n",
    "A __TRUE NEGATIVE (TN)__ is an outcome where the model correctly predicts the negative class.\n",
    "\n",
    "A __FALSE POSITIVE (FP)__ is an outcome where the model incorrectly predicts the positive class.\n",
    "\n",
    "a __FALSE NEGATIVE (FN)__ is an outcome where the model incorrectly predicts the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute primary metrics for logisitc regression\n",
    "# NOTE: All metrics are to be calculated on test dataset\n",
    "# True Positive\n",
    "lr_true_positive = sum([1 for i in range(len(y_test)) if y_test[i] == 1 and y_pred_lr[i] == 1])\n",
    "# True Negative\n",
    "lr_true_negative = sum([1 for i in range(len(y_test)) if y_test[i] == 0 and y_pred_lr[i] == 0])\n",
    "# False Positive\n",
    "lr_false_positive = sum([1 for i in range(len(y_test)) if y_test[i] == 0 and y_pred_lr[i] == 1])\n",
    "# False Negative\n",
    "lr_false_negative = sum([1 for i in range(len(y_test)) if y_test[i] == 1 and y_pred_lr[i] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute primary metrics for decision tree\n",
    "# True Positive\n",
    "dt_true_positive = sum([1 for i in range(len(y_test)) if y_test[i] == 1 and y_pred_dt[i] == 1])\n",
    "# True Negative\n",
    "dt_true_negative = sum([1 for i in range(len(y_test)) if y_test[i] == 0 and y_pred_dt[i] == 0])\n",
    "# False Positive\n",
    "dt_false_positive = sum([1 for i in range(len(y_test)) if y_test[i] == 0 and y_pred_dt[i] == 1])\n",
    "# False Negative\n",
    "dt_false_negative = sum([1 for i in range(len(y_test)) if y_test[i] == 1 and y_pred_dt[i] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "A confusion matrix is visualization technique to summarize the basic performance of a classification algorithm.\n",
    "\n",
    "![Confusion matrix](https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg \"Confusion matric diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix, DO NOT EDIT THE CELL\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25,8))\n",
    "\n",
    "plt.title(\"Confusion matrix for logistic regression\")\n",
    "sns.heatmap(np.array([[lr_true_negative, lr_false_positive],[lr_false_negative, lr_true_positive]]), annot=True, cmap=plt.cm.Blues, fmt='g', ax=axes[0])\n",
    "plt.title(\"Confusion matrix for decision tree\")\n",
    "sns.heatmap(np.array([[dt_true_negative, dt_false_positive],[dt_false_negative, dt_true_positive]]), annot=True, cmap=plt.cm.Blues, fmt='g', ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy \n",
    "Classification accuracy is simply the rate of correct classifications\n",
    "$$Accuracy = \\frac{Number \\, of \\, correct \\, predictions}{Total \\, number \\, of \\, predictions}$$\n",
    "<br>\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification accuracy for logistic regression\n",
    "lr_accuracy = (lr_true_negative+lr_true_positive)/(lr_false_negative+lr_false_positive+lr_true_negative+lr_true_positive)\n",
    "# Classification accuracy for decision tree\n",
    "dt_accuracy = (dt_true_negative+dt_true_positive)/(dt_false_negative+dt_false_positive+dt_true_negative+dt_true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificaton accuracy: LR =  0.9671484888304862\n",
      "Classificaton accuracy: DT =  0.9434954007884363\n"
     ]
    }
   ],
   "source": [
    "print(\"Classificaton accuracy: LR = \" , lr_accuracy)\n",
    "print(\"Classificaton accuracy: DT = \" , dt_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "What proportion of positive identifications was actually correct?\n",
    "$$Precision = \\frac{TP}{TP+FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision for logistic regression\n",
    "try:\n",
    "    lr_precision = lr_true_positive/(lr_true_positive+lr_false_positive)\n",
    "except:\n",
    "    lr_precision = 0\n",
    "    print(\"If you see this message, it means that the\\ndenominator of precision for logistic regression turned out to be 0 \")\n",
    "# Precision for decision tree\n",
    "try:\n",
    "    dt_precision = dt_true_positive/(dt_true_positive+dt_false_positive)\n",
    "except:\n",
    "    dt_precision = 0\n",
    "    print(\"If you see this message, it means that the\\ndenominator of precision for decision tree turned out to be 0 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: LR =  0.3\n",
      "Precision: DT =  0.10714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: LR = \" , lr_precision)\n",
    "print(\"Precision: DT = \" , dt_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "What proportion of actual positives was identified correctly?\n",
    "$$Recall = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall for logistic regression\n",
    "try:\n",
    "    lr_recall = lr_true_positive / (lr_true_positive + lr_false_negative)\n",
    "except:\n",
    "    lr_recall = 0\n",
    "    print(\"If you see this message, it means that the\\ndenominator of recall for logistic regression turned out to be 0 \")\n",
    "# Recall for decision tree\n",
    "try:\n",
    "    dt_recall = dt_true_positive / (dt_true_positive + dt_false_negative) \n",
    "except:\n",
    "    dt_recall = 0\n",
    "    print(\"If you see this message, it means that the\\ndenominator of recall for decision tree turned out to be 0 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: LR =  0.14285714285714285\n",
      "Recall: DT =  0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: LR = \" , lr_recall)\n",
    "print(\"Recall: DT = \" , dt_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score\n",
    "The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.\n",
    "$$ F1 \\, score = \\frac{2* Precision * Recall}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score for logistic regression\n",
    "lr_f1_score = (2*lr_precision*lr_recall)/(lr_precision+lr_recall)\n",
    "# F1 score for decision tree\n",
    "dt_f1_score = (2*dt_precision*dt_recall)/(dt_precision+dt_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: LR =  0.19354838709677416\n",
      "F1 score: DT =  0.12244897959183672\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: LR = \" , lr_f1_score)\n",
    "print(\"F1 score: DT = \" , dt_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve\n",
    "A ROC Curve is a plot of the true positive rate and the false positive rate for a given set of probability predictions at different thresholds used to map the probabilities to class labels. The area under the curve is then the approximate integral under the ROC Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive rate for logisitic regression\n",
    "lr_false_positive_rate = \n",
    "# True positive rate for logisitic regression\n",
    "lr_true_positive_rate = \n",
    "# False positive rate for decision trees\n",
    "dt_false_positive_rate = \n",
    "# True positive rate for decision trees\n",
    "dt_true_positive_rate = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the ROC curve\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
