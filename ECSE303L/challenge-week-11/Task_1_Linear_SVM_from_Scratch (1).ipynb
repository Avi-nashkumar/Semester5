{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_1_Linear_SVM_from_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tcuiFmIToA"
      },
      "source": [
        "#Support vector machine-based software reuse prediction\n",
        "\n",
        "## Objective: To implement SVM from scratch and also compared it with using sklearn's SVM\n",
        "\n",
        "Source of SVM: https://dzone.com/articles/classification-from-scratch-svm-78\n",
        "\n",
        "In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. SVM presents one of the most robust prediction methods, based on the statistical learning framework. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall.\n",
        "\n",
        "In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
        "\n",
        "\n",
        "### 1. For all ti in training set:\n",
        " ti.w + b <= -1   if yi = -1 \n",
        "\n",
        " ti.w + b >= +1 if yi = +1 \n",
        "\n",
        "or\n",
        "\n",
        "yi(ti.w+b) >= 1\n",
        "\n",
        "###2. for all support vectors (i.e., data points that defines margin)\n",
        "  ti.w+b = -1    where ti is -ve support vector and yi is -1\n",
        "\n",
        "  ti.w+b = +1    where ti is +ve support vector and yi is +1\n",
        "\n",
        "###3. For decision Boundary i.e., yi(ti.w+b)=0 where ti lies within decision boundary\n",
        "### 4. The goal is to maximize width (W) or to minimize |w|\n",
        "\n",
        "W = ((X+ - X-).w)/|w|\n",
        "\n",
        "### 5. After obtaining the tuned w and b we have\n",
        "\n",
        "x.w+b = 1 is line passing through +ve support vectors\n",
        "\n",
        "x.w+b = -1 is line passing through -ve support vectors\n",
        "\n",
        "x.w+b = 0 is decision boundary\n",
        "\n",
        "### 6. As you know it is not possible that the support vector lines always pass through support vectors\n",
        "\n",
        "### 7. Thus, it is a convex optimization issue and will lead to a global minimum\n",
        "\n",
        "### 8. This is Linear SVM i.e., kernel is linear\n",
        "\n",
        "#Dataset: Reuse/predicting successful reuse\n",
        "\n",
        "# Attribute Information:\n",
        "1.  Project ID {A,B,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y}\n",
        "2.  Software Staff {L,M,S}\n",
        "3.  Overall Staff {L,X,M,S}\n",
        "4.  Type of Software Production {product-family,isolated}\n",
        "5.  Software and Product {product,alone,process,NA}\n",
        "6.  SP maturity {high,middle,low}\n",
        "7.  Application Domain {TLC,SE-Tools,Bank,Engine_Controller,FMS,ATC,TS,Space Manufacturing,Measurement,Finance,Book-Keeping}\n",
        "8.  Type of Software {Technical,Business,Embedded-RT,Non-Embedded-RT}\n",
        "9.  Size of Baseline {L,M,S,not_available}\n",
        "10. Development Approach {OO,proc,not_available}\n",
        "11. Staff Experience {high,middle,low,not_available}\n",
        "12. Top Management Commitment {yes,no}\n",
        "13. Key Reuse Roles Introduced {yes,no,NA}\n",
        "14. Reuse Processes Introduced {yes,no,NA}\n",
        "15. Non-Reuse Processes Modified {yes,no,NA}\n",
        "16. Repository {yes,NA}\n",
        "17. Human Factors {yes,no}\n",
        "18. Reuse Approach {tight,loose,NA}\n",
        "19. Work Products {D+C,C,R+D+C,NA}\n",
        "20. Domain Analysis {yes,no,NA}\n",
        "21. Origin {ex-novo,as-is,reeng,NA}\n",
        "22. Independent Team {yes,no,NA}\n",
        "23. When Assests Developed {before,justintime,NA}\n",
        "24. Qualification {yes,no,NA}\n",
        "25. Configuration Management {yes,no,NA}\n",
        "26. Rewards Policy {no,yes}\n",
        "27. Assests {51_to_100,21_to_50,100+,1_to_20,NA}\n",
        "\n",
        "#Target classes \n",
        "Success or Failure {success,failure}\n",
        "\n",
        "#Source: http://promise.site.uottawa.ca/SERepository/datasets/reuse.arff\n",
        "\n",
        "#Tasks:\n",
        "1. Initially, load arff dataset\n",
        "2. Apply pre-processing techniques\n",
        "3. Divide data into training and testing sets.\n",
        "4. Build SVM model from scratch\n",
        "5. Test your own SVM model\n",
        "6. Obtain precision and recall\n",
        "7. Implement sklearn's model on processed data\n",
        "8. Compare your SVM model with sklearn's model\n",
        "\n",
        "##Task 1: Implement linear SVM from scratch  \n",
        "# Algorithm of Linear SVM\n",
        "1.  Initialize with random big value of w say(w0,w0) we will decrease it later\n",
        "2.  Set step size as w0*0.1\n",
        "3.  A minimum value of b, may increase it during the process\n",
        "\n",
        "        i.  b will range from (-b0 < b < +b0, step = step*b_multiple)\n",
        "\n",
        "        ii. It is also computational extensive. Therefore, define b0 wisely\n",
        "4.  Check for points ti in dataset:\n",
        "\n",
        "        i.  Check all transformation of w like (w0,w0), (-w0,w0), (w0,-w0), (-w0,-w0)\n",
        "\n",
        "        ii. if not yi(ti.w+b)>=1 for all points then break\n",
        "\n",
        "        iii.  Else evaluate |w| and put it in dictionary as key and (w,b) as values\n",
        "5.  If w<=0 then current step is completed and move to step 6\n",
        "\n",
        "        Else minimize w as (w0-step,w0-step) and move to step 3\n",
        "6.  While step not becomes w0*0.001 \n",
        "\n",
        "        i.  step = step*0.1\n",
        "\n",
        "        ii. move to step 3\n",
        "\n",
        "7.  Select (w,b) that contain minimum |w| form the dictionary\n",
        "\n",
        "##Task 2: Implement sklearn's SVM\n",
        "\n",
        "##Task 3: Compare your SVM with sklearn's SVM with concluding remarks\n",
        "\n",
        "#Helping links:\n",
        "\n",
        "https://pythonprogramming.net/svm-in-python-machine-learning-tutorial/\n",
        "\n",
        "https://medium.com/deep-math-machine-learning-ai/chapter-3-1-svm-from-scratch-in-python-86f93f853dc\n",
        "\n",
        "https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/\n",
        "\n",
        "http://ecomunsing.com/build-your-own-support-vector-machine\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yGvcerZa0S8"
      },
      "source": [
        "## Task 1: Implement linear SVM from scratch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duh_Q74qIidS"
      },
      "source": [
        "# Load the libraries\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyioH2iYIjhk"
      },
      "source": [
        "# Load the arff dataset \n",
        "# Shuffel the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtfupr9JInhf"
      },
      "source": [
        "# Preprocessing\n",
        "# Encoding categorical variables (if any)\n",
        "# Feature Scaling\n",
        "# Filling missing values (if any)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13owZH7mIpZp"
      },
      "source": [
        "# Divide the dataset to training and testing set\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KEJ1BB8a5xQ"
      },
      "source": [
        "# Implement SVM from scratch \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOIhehoYbSsJ"
      },
      "source": [
        "# Train and test your SVM models\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUBOrqrbbX-u"
      },
      "source": [
        "# Evaluate training and testing precision and recall\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hZF7xcjbdAF"
      },
      "source": [
        "##Task 2: Implement sklearn's SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DSX6JMEbfss"
      },
      "source": [
        "# Use the preprocessed dataset here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yqNwnVCbkxG"
      },
      "source": [
        "# Divide the dataset to training and testing set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB_I4407bns6"
      },
      "source": [
        "# Train SVM model using sklearn's SVM\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHOGKAXiCsSN"
      },
      "source": [
        "# Evaluate training and testing precision and recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK086juobpRo"
      },
      "source": [
        "# Play with the intial/hyper parameters of the models(Optional)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPw_-SMyrka_"
      },
      "source": [
        "\n",
        "##Task 3: Compare your SVM with sklearn's SVM with concluding remarks\n"
      ]
    }
  ]
}