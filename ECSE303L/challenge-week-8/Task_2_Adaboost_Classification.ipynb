{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_tcuiFmIToA"
   },
   "source": [
    "# Congressional Voting Classification\n",
    "\n",
    "#Objective\n",
    "The main objective is to predict whether congressmen is Democrat or Republican based on voting patterns by using the decision tree with the adaboost.\n",
    "\n",
    "#Adaboost\n",
    "AdaBoost is an ensemble learning method (also known as “meta-learning”) which was initially created to increase the efficiency of binary classifiers. AdaBoost uses an iterative approach to learn from the mistakes of weak classifiers, and turn them into strong ones.\n",
    "\n",
    "\n",
    "#Data Set\n",
    "This data set includes votes for each of the U.S. House of Representatives Congressmen on the 16 key votes identified by the CQA. The CQA lists nine different types of votes: voted for, paired for, and announced for (these three simplified to yea), voted against, paired against, and announced against (these three simplified to nay), voted present, voted present to avoid conflict of interest, and did not vote or otherwise make a position known (these three simplified to an unknown disposition).\n",
    "\n",
    "\n",
    "##Attribute Information:\n",
    "1. Class Name: 2 (democrat, republican)\n",
    "2. handicapped-infants: 2 (y,n)\n",
    "3. water-project-cost-sharing: 2 (y,n)\n",
    "4. adoption-of-the-budget-resolution: 2 (y,n)\n",
    "5. physician-fee-freeze: 2 (y,n)\n",
    "6. el-salvador-aid: 2 (y,n)\n",
    "7. religious-groups-in-schools: 2 (y,n)\n",
    "8. anti-satellite-test-ban: 2 (y,n)\n",
    "9. aid-to-nicaraguan-contras: 2 (y,n)\n",
    "10. mx-missile: 2 (y,n)\n",
    "11. immigration: 2 (y,n)\n",
    "12. synfuels-corporation-cutback: 2 (y,n)\n",
    "13. education-spending: 2 (y,n)\n",
    "14. superfund-right-to-sue: 2 (y,n)\n",
    "15. crime: 2 (y,n)\n",
    "16. duty-free-exports: 2 (y,n)\n",
    "17. export-administration-act-south-africa: 2 (y,n)\n",
    "\n",
    "\n",
    "\n",
    "#Source\n",
    "The dataset can be obtained from the:\n",
    "https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records\n",
    "\n",
    "#Tasks:\n",
    "1.\tObtained the dataset\n",
    "2.\tApply pre-processing operations\n",
    "3.\tTrain Adaboost model from scratch and test the model\n",
    "4.\tTrain Adaboost model using sklearn\n",
    "6.\tCompare the performance of Adaboost, Random Forest and Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yGvcerZa0S8"
   },
   "source": [
    "## Part 1: Adaboost from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Duh_Q74qIidS"
   },
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyioH2iYIjhk"
   },
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtfupr9JInhf"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Encoding categorical variables (if any)\n",
    "# Feature Scaling\n",
    "# Filling missing values (if any)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13owZH7mIpZp"
   },
   "outputs": [],
   "source": [
    "# Divide the dataset to training and testing set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KEJ1BB8a5xQ"
   },
   "outputs": [],
   "source": [
    "# Implement Adaboost model from scratch\n",
    "# Adaboost consist of stumps which can be created using builtin decision trees in sklearn\n",
    "# Stump can be trained by keeping the max_depth as 1\n",
    "class DecisionStumps:\n",
    "    def __init__(self):\n",
    "        self.polarity=1\n",
    "        self.feature_idx= None\n",
    "        self.threshold= None\n",
    "        slef.alpha= None\n",
    "    def predict(self,X):\n",
    "        n_samples= X.shape[0]\n",
    "        X_column= X[:, self.feature_idx]\n",
    "        predictions= np.ones(n_samples)\n",
    "        \n",
    "        if(self.polarity==1):\n",
    "            predictions[X_columns<self.threshold]=-1\n",
    "        else:\n",
    "            predictions[X_columns>self.threshold]=1\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost:\n",
    "    def __init__(self,n_clf=5):\n",
    "        self.n_clf= n_clf\n",
    "    def fit(self,X,y):\n",
    "        n_samples, n_features= X.shape[0]\n",
    "        w= np.full(n_samples,(1/n_samples))\n",
    "        \n",
    "        self.clfs=[]\n",
    "        for _ in self.n_clf:\n",
    "            clf= DecisionStump()\n",
    "            \n",
    "            \n",
    "            min_error= float('inf')\n",
    "            for feature_i in range(n_features):\n",
    "                X_column= X[:, self.feature_i]\n",
    "                thresholds= np.unique(X_columns)\n",
    "                for threshold in thresholds:\n",
    "                    p=1\n",
    "                    predictions= np.ones(n_samples)\n",
    "                    predictions[X_columns<polarity]=-1\n",
    "                    misclassified= w[y!= predictions]\n",
    "                    error= sum(misclassified)\n",
    "                    \n",
    "                    if error>0.5:\n",
    "                        error= 1-error\n",
    "                        p=-1\n",
    "                    if error<min_error:\n",
    "                        min_error= error\n",
    "                        clf.polarity=p\n",
    "                        clf.threshold= threshold\n",
    "                        clf.feature_idx= feature_i\n",
    "            EPS=1e-10\n",
    "            clf.alpha= 0.5*np.log((1-error)/(error+EPS))\n",
    "            predictions= clf.predict(X)\n",
    "            w*= np.exp(clf.alpha*y*predictions)\n",
    "            w/= np.sum(w)\n",
    "            \n",
    "            self.clfs.append(clf)\n",
    "            \n",
    "            \n",
    "    def predict(self,X):\n",
    "        clf_preds=[clf.alpha* clf.predict(X) for i in self.clfs ]\n",
    "        y_pred= np.sum(clf_preds, axis=0)\n",
    "        y_pred= np.sign(y_pred)\n",
    "        return y_pred\n",
    "            \n",
    "                \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jOIhehoYbSsJ"
   },
   "outputs": [],
   "source": [
    "# Train the model and test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUBOrqrbbX-u"
   },
   "outputs": [],
   "source": [
    "# Evaluate the results using accuracy, precision, recall and f-measure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hZF7xcjbdAF"
   },
   "source": [
    "## Part 2: Adaboost using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DSX6JMEbfss"
   },
   "outputs": [],
   "source": [
    "# Use the preprocessed dataset here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yqNwnVCbkxG"
   },
   "outputs": [],
   "source": [
    "# Train the Adaboost Model using builtin Sklearn Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB_I4407bns6"
   },
   "outputs": [],
   "source": [
    "# Test the model with testing set and print the accuracy, precision, recall and f-measure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aK086juobpRo"
   },
   "outputs": [],
   "source": [
    "# Play with parameters such as\n",
    "# number of decision trees\n",
    "# Criterion for splitting\n",
    "# Max depth\n",
    "# Minimum samples per split and leaf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08GzOdPKbqPg"
   },
   "source": [
    "## Part 3: Compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr91M76xbtc0"
   },
   "outputs": [],
   "source": [
    "# Train Adaboost, Random Forest and Decision tree models from sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPPI9vK_bzLz"
   },
   "outputs": [],
   "source": [
    "# Run the model on testing set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdSk17pkb25Q"
   },
   "outputs": [],
   "source": [
    "# Compare their accuracy, precision, recall and f-measure\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Task 2 - Adaboost Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
